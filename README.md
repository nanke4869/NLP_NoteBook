# NLP_NoteBook

1. Basic Embedding Model

- 1-1. [NNLM(Neural Network Language Model)](https://github.com/nanke4869/NLP_NoteBook/tree/main/1_1%20NNLM) - Predict Next Word
  - Paper - [A Neural Probabilistic Language Model(2003)](http://www.jmlr.org/papers/volume3/bengio03a/bengio03a.pdf)
- 1-2. [Word2Vec(Skip-gram)](https://github.com/nanke4869/NLP_NoteBook/tree/main/1_2%20Word2Vec) - Embedding Words and Show Graph
  - Paper - [Distributed Representations of Words and Phrases and their Compositionality(2013)](https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)

2. CNN(Convolutional Neural Network)
- 2-1. [TextCNN](https://github.com/nanke4869/NLP_NoteBook/tree/main/3_1%20TextRNN) - Binary Sentiment Classification
  - Paper - [Convolutional Neural Networks for Sentence Classification(2014)](http://www.aclweb.org/anthology/D14-1181)

3. RNN(Recurrent Neural Network)
- 3-1. [TextRNN](https://github.com/nanke4869/NLP_NoteBook/tree/main/3_1%20TextRNN) - Predict Next Step
  - Paper - [Finding Structure in Time(1990)](http://psych.colorado.edu/~kimlab/Elman1990.pdf)
- 3-2. [TextLSTM](https://github.com/nanke4869/NLP_NoteBook/tree/main/3_2%20TextLSTM) - Autocomplete
  - Paper - [LONG SHORT-TERM MEMORY(1997)](https://www.bioinf.jku.at/publications/older/2604.pdf)
- 3-3. [Bi-LSTM](https://github.com/nanke4869/NLP_NoteBook/tree/main/3_3%20BiLSTM) - Predict Next Word in Long Sentence

4. Attention Mechanism
- 4-1. [Seq2Seq](https://github.com/nanke4869/NLP_NoteBook/tree/main/4_1%20Seq2Seq) - Change Word
  - Paper - [Learning Phrase Representations using RNN Encoderâ€“Decoder for Statistical Machine Translation(2014)](https://arxiv.org/pdf/1406.1078.pdf)
- 4-2. [Seq2Seq with Attention](https://github.com/nanke4869/NLP_NoteBook/tree/main/4_2%20Seq2Seq%2BAttention) - Translate
  - Paper - [Neural Machine Translation by Jointly Learning to Align and Translate(2014)](https://arxiv.org/abs/1409.0473)
- 4-3. [Bi-LSTM with Attention](https://github.com/nanke4869/NLP_NoteBook/tree/main/4_3%20BiLSTM%2BAttention) - Binary Sentiment Classification

5. Model based on Transformer
- 5-1. [The Transformer](https://github.com/nanke4869/NLP_NoteBook/tree/main/5_1%20Transformer) - Translate
  - Paper - [Attention Is All You Need(2017)](https://arxiv.org/abs/1706.03762)
- 5-2. [BERT](https://github.com/nanke4869/NLP_NoteBook/tree/main/5_2%20BERT) - Classification Next Sentence & Predict Masked Tokens
  - Paper - [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding(2018)](https://arxiv.org/abs/1810.04805)
